{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAGE 3 DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/processed/DOE_Stage_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Time Event Began</th>\n",
       "      <th>Time of Restoration</th>\n",
       "      <th>Area Affected</th>\n",
       "      <th>NERC Region</th>\n",
       "      <th>Alert Criteria</th>\n",
       "      <th>Event Type</th>\n",
       "      <th>Demand Loss (MW)</th>\n",
       "      <th>Number of Customers Affected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January</td>\n",
       "      <td>2002-01-29 16:00:00</td>\n",
       "      <td>2002-01-29 19:30:00</td>\n",
       "      <td>Metropolitan Kansas City Area</td>\n",
       "      <td>SPP</td>\n",
       "      <td>Unkown</td>\n",
       "      <td>Severe Weather - Winter/Snow/Ice</td>\n",
       "      <td>600.0</td>\n",
       "      <td>270000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>January</td>\n",
       "      <td>2002-01-30 06:00:00</td>\n",
       "      <td>2002-01-30 12:00:00</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>SPP</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Severe Weather - Winter/Snow/Ice</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1881134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January</td>\n",
       "      <td>2002-01-30 16:00:00</td>\n",
       "      <td>2002-01-30 21:00:00</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>SPP</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Severe Weather - Winter/Snow/Ice</td>\n",
       "      <td>210.0</td>\n",
       "      <td>95000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February</td>\n",
       "      <td>2002-02-27 10:48:00</td>\n",
       "      <td>2002-02-27 11:35:00</td>\n",
       "      <td>California</td>\n",
       "      <td>WECC</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unkown/Unspecified</td>\n",
       "      <td>300.0</td>\n",
       "      <td>255000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>March</td>\n",
       "      <td>2002-03-09 00:00:00</td>\n",
       "      <td>2002-03-09 12:00:00</td>\n",
       "      <td>Lower Peninsula of Michigan</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Severe Weather - Unspecified/Other</td>\n",
       "      <td>190.0</td>\n",
       "      <td>190000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Month    Time Event Began Time of Restoration  \\\n",
       "0   January 2002-01-29 16:00:00 2002-01-29 19:30:00   \n",
       "1   January 2002-01-30 06:00:00 2002-01-30 12:00:00   \n",
       "2   January 2002-01-30 16:00:00 2002-01-30 21:00:00   \n",
       "3  February 2002-02-27 10:48:00 2002-02-27 11:35:00   \n",
       "4     March 2002-03-09 00:00:00 2002-03-09 12:00:00   \n",
       "\n",
       "                   Area Affected NERC Region Alert Criteria  \\\n",
       "0  Metropolitan Kansas City Area         SPP         Unkown   \n",
       "1                       Oklahoma         SPP        Unknown   \n",
       "2                       Missouri         SPP        Unknown   \n",
       "3                     California        WECC        Unknown   \n",
       "4    Lower Peninsula of Michigan         RFC        Unknown   \n",
       "\n",
       "                           Event Type  Demand Loss (MW)  \\\n",
       "0    Severe Weather - Winter/Snow/Ice             600.0   \n",
       "1    Severe Weather - Winter/Snow/Ice             500.0   \n",
       "2    Severe Weather - Winter/Snow/Ice             210.0   \n",
       "3                  Unkown/Unspecified             300.0   \n",
       "4  Severe Weather - Unspecified/Other             190.0   \n",
       "\n",
       "   Number of Customers Affected  \n",
       "0                      270000.0  \n",
       "1                     1881134.0  \n",
       "2                       95000.0  \n",
       "3                      255000.0  \n",
       "4                      190000.0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = df.columns.tolist()\n",
    "df = df.rename(str.lower, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3892 entries, 0 to 3891\n",
      "Data columns (total 9 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   month                         3892 non-null   object        \n",
      " 1   time event began              3892 non-null   datetime64[ns]\n",
      " 2   time of restoration           3892 non-null   datetime64[ns]\n",
      " 3   area affected                 3892 non-null   object        \n",
      " 4   nerc region                   3892 non-null   object        \n",
      " 5   alert criteria                3892 non-null   object        \n",
      " 6   event type                    3892 non-null   object        \n",
      " 7   demand loss (mw)              2441 non-null   float64       \n",
      " 8   number of customers affected  3157 non-null   float64       \n",
      "dtypes: datetime64[ns](2), float64(2), object(5)\n",
      "memory usage: 273.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['demand loss (mw)'] = pd.to_numeric(df['demand loss (mw)'], errors='coerce')\n",
    "df['number of customers affected'] = pd.to_numeric(df['number of customers affected'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3892 entries, 0 to 3891\n",
      "Data columns (total 9 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   month                         3892 non-null   object        \n",
      " 1   time event began              3892 non-null   datetime64[ns]\n",
      " 2   time of restoration           3892 non-null   datetime64[ns]\n",
      " 3   area affected                 3892 non-null   object        \n",
      " 4   nerc region                   3892 non-null   object        \n",
      " 5   alert criteria                3892 non-null   object        \n",
      " 6   event type                    3892 non-null   object        \n",
      " 7   demand loss (mw)              3892 non-null   float64       \n",
      " 8   number of customers affected  3892 non-null   Int64         \n",
      "dtypes: Int64(1), datetime64[ns](2), float64(1), object(5)\n",
      "memory usage: 277.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month                           763\n",
      "time event began                763\n",
      "time of restoration             763\n",
      "area affected                   763\n",
      "nerc region                     763\n",
      "alert criteria                  763\n",
      "event type                      763\n",
      "demand loss (mw)                763\n",
      "number of customers affected    763\n",
      "duration                        763\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the duration column\n",
    "df['duration'] = df['time of restoration'] - df['time event began']\n",
    "\n",
    "# Filter rows with negative duration\n",
    "negative_duration_df = df[df['duration'] < pd.Timedelta(0)]\n",
    "\n",
    "# Display the DataFrame with negative duration\n",
    "print(negative_duration_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where the date difference is negative and 'time of restoration' starts with 00: and has minutes\n",
    "mask = (df['time of restoration'].dt.strftime('%H:%M') == '00:') & (df['time of restoration'].dt.minute > 0) & (df['time of restoration'] < df['time event began'])\n",
    "\n",
    "# Add a day to 'time of restoration' for rows where the mask is True\n",
    "df.loc[mask, 'time of restoration'] += pd.DateOffset(days=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>time event began</th>\n",
       "      <th>time of restoration</th>\n",
       "      <th>area affected</th>\n",
       "      <th>nerc region</th>\n",
       "      <th>alert criteria</th>\n",
       "      <th>event type</th>\n",
       "      <th>demand loss (mw)</th>\n",
       "      <th>number of customers affected</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>January</td>\n",
       "      <td>2002-01-29 16:00:00</td>\n",
       "      <td>2002-01-29 19:30:00</td>\n",
       "      <td>Metropolitan Kansas City Area</td>\n",
       "      <td>SPP</td>\n",
       "      <td>Unkown</td>\n",
       "      <td>Severe Weather - Winter/Snow/Ice</td>\n",
       "      <td>600.0</td>\n",
       "      <td>270000</td>\n",
       "      <td>0 days 03:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>January</td>\n",
       "      <td>2002-01-30 06:00:00</td>\n",
       "      <td>2002-01-30 12:00:00</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>SPP</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Severe Weather - Winter/Snow/Ice</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1881134</td>\n",
       "      <td>0 days 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January</td>\n",
       "      <td>2002-01-30 16:00:00</td>\n",
       "      <td>2002-01-30 21:00:00</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>SPP</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Severe Weather - Winter/Snow/Ice</td>\n",
       "      <td>210.0</td>\n",
       "      <td>95000</td>\n",
       "      <td>0 days 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February</td>\n",
       "      <td>2002-02-27 10:48:00</td>\n",
       "      <td>2002-02-27 11:35:00</td>\n",
       "      <td>California</td>\n",
       "      <td>WECC</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unkown/Unspecified</td>\n",
       "      <td>300.0</td>\n",
       "      <td>255000</td>\n",
       "      <td>0 days 00:47:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>March</td>\n",
       "      <td>2002-03-09 00:00:00</td>\n",
       "      <td>2002-03-09 12:00:00</td>\n",
       "      <td>Lower Peninsula of Michigan</td>\n",
       "      <td>RFC</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Severe Weather - Unspecified/Other</td>\n",
       "      <td>190.0</td>\n",
       "      <td>190000</td>\n",
       "      <td>0 days 12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      month    time event began time of restoration  \\\n",
       "0   January 2002-01-29 16:00:00 2002-01-29 19:30:00   \n",
       "1   January 2002-01-30 06:00:00 2002-01-30 12:00:00   \n",
       "2   January 2002-01-30 16:00:00 2002-01-30 21:00:00   \n",
       "3  February 2002-02-27 10:48:00 2002-02-27 11:35:00   \n",
       "4     March 2002-03-09 00:00:00 2002-03-09 12:00:00   \n",
       "\n",
       "                   area affected nerc region alert criteria  \\\n",
       "0  Metropolitan Kansas City Area         SPP         Unkown   \n",
       "1                       Oklahoma         SPP        Unknown   \n",
       "2                       Missouri         SPP        Unknown   \n",
       "3                     California        WECC        Unknown   \n",
       "4    Lower Peninsula of Michigan         RFC        Unknown   \n",
       "\n",
       "                           event type  demand loss (mw)  \\\n",
       "0    Severe Weather - Winter/Snow/Ice             600.0   \n",
       "1    Severe Weather - Winter/Snow/Ice             500.0   \n",
       "2    Severe Weather - Winter/Snow/Ice             210.0   \n",
       "3                  Unkown/Unspecified             300.0   \n",
       "4  Severe Weather - Unspecified/Other             190.0   \n",
       "\n",
       "   number of customers affected        duration  \n",
       "0                        270000 0 days 03:30:00  \n",
       "1                       1881134 0 days 06:00:00  \n",
       "2                         95000 0 days 05:00:00  \n",
       "3                        255000 0 days 00:47:00  \n",
       "4                        190000 0 days 12:00:00  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_diff_mask = df['time of restoration'] < df['time event began']\n",
    "\n",
    "# Swap dates for rows with negative date difference\n",
    "df.loc[negative_diff_mask, ['time event began', 'time of restoration']] = df.loc[negative_diff_mask, ['time of restoration', 'time event began']].values\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "month                           0\n",
      "time event began                0\n",
      "time of restoration             0\n",
      "area affected                   0\n",
      "nerc region                     0\n",
      "alert criteria                  0\n",
      "event type                      0\n",
      "demand loss (mw)                0\n",
      "number of customers affected    0\n",
      "duration                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the duration column\n",
    "df['duration'] = df['time of restoration'] - df['time event began']\n",
    "\n",
    "# Filter rows with negative duration\n",
    "negative_duration_df = df[df['duration'] < pd.Timedelta(0)]\n",
    "\n",
    "# Display the DataFrame with negative duration\n",
    "print(negative_duration_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('duration', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "# Function to extract only state names from 'Area Affected'\n",
    "def extract_states(area):\n",
    "    # Use a regular expression to find state names (assuming state names start with an uppercase letter)\n",
    "    states = re.findall(r'\\b[A-Z][a-z]*\\b', area)\n",
    "    return states\n",
    "\n",
    "df['state_temp'] = df['area affected'].apply(extract_states) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US and Canada - Ontario excluded due to US counties with similar names. Will manually validate\n",
    "valid_locations = [\n",
    "    'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n",
    "    'Delaware', 'District of Columbia', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois',\n",
    "    'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts',\n",
    "    'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
    "    'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota',\n",
    "    'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina',\n",
    "    'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont','West Virginia','Virginia', 'Washington',\n",
    "    'Wisconsin', 'Wyoming','Puerto Rico', 'Nova Scocia', 'manitoba', 'Quebec', 'Alberta', 'Saskatchewan',\n",
    "    'British Columbia','Prince Edward Island', 'New Brunswick'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter only valid state names from the list\n",
    "def second_extract_states(state_list):\n",
    "    return [state for state in state_list if state in valid_locations]\n",
    "\n",
    "# Apply the function to create the 'state' column\n",
    "df['state'] = df['state_temp'].apply(second_extract_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2 = df2.rename(str.upper, axis='columns')\n",
    "\n",
    "df2.to_excel('../data/processed/DOE_Stage_3-1.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_excel('../data/processed/DOE_Stage_3-1.xlsx')\n",
    "df3 = df3.rename(str.upper, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually save `DOE_Stage_3-2.xlsx` and clean state data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_excel('../data/processed/DOE_Stage_3-2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3892 entries, 0 to 3891\n",
      "Data columns (total 11 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   MONTH                         3892 non-null   object        \n",
      " 1   TIME EVENT BEGAN              3892 non-null   datetime64[ns]\n",
      " 2   TIME OF RESTORATION           3892 non-null   datetime64[ns]\n",
      " 3   AREA AFFECTED                 3892 non-null   object        \n",
      " 4   NERC REGION                   3892 non-null   object        \n",
      " 5   ALERT CRITERIA                3892 non-null   object        \n",
      " 6   EVENT TYPE                    3892 non-null   object        \n",
      " 7   Demand Loss (MW)              2441 non-null   float64       \n",
      " 8   Number of Customers Affected  3157 non-null   float64       \n",
      " 9   STATE_TEMP                    3892 non-null   object        \n",
      " 10  STATE 3                       3892 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(2), object(7)\n",
      "memory usage: 334.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = pd.concat([df3, df4['STATE 3']], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_excel('../data/processed/DOE_Stage_3-3.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3_3 =pd.read_excel('../data/processed/DOE_Stage_3-3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3892 entries, 0 to 3891\n",
      "Data columns (total 11 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   MONTH                         3892 non-null   object        \n",
      " 1   TIME EVENT BEGAN              3892 non-null   datetime64[ns]\n",
      " 2   TIME OF RESTORATION           3892 non-null   datetime64[ns]\n",
      " 3   AREA AFFECTED                 3892 non-null   object        \n",
      " 4   NERC REGION                   3892 non-null   object        \n",
      " 5   ALERT CRITERIA                3892 non-null   object        \n",
      " 6   EVENT TYPE                    3892 non-null   object        \n",
      " 7   Demand Loss (MW)              2441 non-null   float64       \n",
      " 8   Number of Customers Affected  3157 non-null   float64       \n",
      " 9   STATE_temp                    3892 non-null   object        \n",
      " 10  STATE                         3892 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(2), object(7)\n",
      "memory usage: 334.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_3_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3_3 = df_3_3.drop(['STATE_temp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3_3.to_excel('../data/processed/DOE_Stage_3-4.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3_4 = pd.read_excel('../data/processed/DOE_Stage_3-4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    }
   ],
   "source": [
    "# Find duplicate dates\n",
    "duplicate_dates = df_3_4[df_3_4.duplicated('TIME EVENT BEGAN', keep=False)]['TIME EVENT BEGAN']\n",
    "\n",
    "print(duplicate_dates.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_dates.to_excel('../data/processed/duplicate-dates.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3_4.to_excel('../data/processed/DOE_Stage_3-5.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually review and clean duplicate data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df_3_5 = pd.read_excel('../data/processed/DOE_Stage_3-5.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3834 entries, 0 to 3833\n",
      "Data columns (total 10 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   month                         3834 non-null   object        \n",
      " 1   time event began              3834 non-null   datetime64[ns]\n",
      " 2   time of restoration           3834 non-null   datetime64[ns]\n",
      " 3   area affected                 3834 non-null   object        \n",
      " 4   nerc region                   3834 non-null   object        \n",
      " 5   alert criteria                3834 non-null   object        \n",
      " 6   event type                    3834 non-null   object        \n",
      " 7   demand loss (mw)              2409 non-null   float64       \n",
      " 8   number of customers affected  3124 non-null   float64       \n",
      " 9   state                         3834 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(2), object(6)\n",
      "memory usage: 299.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_3_5 = df_3_5.rename(str.lower, axis='columns')\n",
    "df_3_5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    757.000000\n",
       "mean       3.182299\n",
       "std        7.509504\n",
       "min        0.000000\n",
       "25%        1.000000\n",
       "50%        1.000000\n",
       "75%        3.000000\n",
       "max       94.000000\n",
       "Name: demand loss (mw), dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_5.groupby(['event type','state'])['demand loss (mw)'].count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    198.000000\n",
       "mean      12.166667\n",
       "std       30.533455\n",
       "min        0.000000\n",
       "25%        1.000000\n",
       "50%        1.000000\n",
       "75%        7.000000\n",
       "max      305.000000\n",
       "Name: demand loss (mw), dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_5.groupby(['event type','nerc region'])['demand loss (mw)'].count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw_state_grouped_data = df_3_5.groupby(['event type', 'state'])['demand loss (mw)'].count()\n",
    "\n",
    "# Find group combinations with count 0\n",
    "mw_state_groups_with_zero_count = mw_state_grouped_data[mw_state_grouped_data == 0].index\n",
    "\n",
    "len(mw_state_groups_with_zero_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw_nerc_grouped_data = df_3_5.groupby(['event type', 'nerc region'])['demand loss (mw)'].count()\n",
    "\n",
    "# Find group combinations with count 0\n",
    "mw_nerc_groups_with_zero_count = mw_nerc_grouped_data[mw_nerc_grouped_data == 0].index\n",
    "\n",
    "len(mw_nerc_groups_with_zero_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw_et_grouped_data = df_3_5.groupby(['event type'])['demand loss (mw)'].count()\n",
    "\n",
    "# Find group combinations with count 0\n",
    "mw_et_groups_with_zero_count = mw_et_grouped_data[mw_et_grouped_data == 0].index\n",
    "\n",
    "len(mw_et_groups_with_zero_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    757.000000\n",
       "mean       4.126816\n",
       "std        9.234728\n",
       "min        0.000000\n",
       "25%        1.000000\n",
       "50%        1.000000\n",
       "75%        3.000000\n",
       "max      102.000000\n",
       "Name: number of customers affected, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_5.groupby(['event type', 'state'])['number of customers affected'].count().describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    198.000000\n",
       "mean      15.777778\n",
       "std       39.032735\n",
       "min        0.000000\n",
       "25%        1.000000\n",
       "50%        2.000000\n",
       "75%        8.750000\n",
       "max      332.000000\n",
       "Name: number of customers affected, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_5.groupby(['event type','nerc region'])['number of customers affected'].count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cus_state_grouped_data = df_3_5.groupby(['event type', 'state'])['number of customers affected'].count()\n",
    "\n",
    "# Find group combinations with count 0\n",
    "cus_state_groups_with_zero_count = cus_state_grouped_data[cus_state_grouped_data == 0].index\n",
    "\n",
    "len(cus_state_groups_with_zero_count)\n",
    "\n",
    "# print(length_of_zero_count_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cus_nerc_grouped_data = df_3_5.groupby(['event type', 'nerc region'])['number of customers affected'].count()\n",
    "\n",
    "# Find group combinations with count 0\n",
    "cus_nerc_groups_with_zero_count = cus_nerc_grouped_data[cus_nerc_grouped_data == 0].index\n",
    "\n",
    "len(cus_nerc_groups_with_zero_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cus_et_grouped_data = df_3_5.groupby(['event type'])['number of customers affected'].count()\n",
    "\n",
    "# Find group combinations with count 0\n",
    "cus_et_groups_with_zero_count = cus_et_grouped_data[cus_et_grouped_data == 0].index\n",
    "\n",
    "len(cus_et_groups_with_zero_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['month',\n",
       " 'time event began',\n",
       " 'time of restoration',\n",
       " 'area affected',\n",
       " 'nerc region',\n",
       " 'alert criteria',\n",
       " 'event type',\n",
       " 'demand loss (mw)',\n",
       " 'number of customers affected',\n",
       " 'state']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_5.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['month',\n",
    " 'time event began',\n",
    " 'time of restoration',\n",
    " 'area affected',\n",
    " 'nerc region',\n",
    " 'alert criteria',\n",
    " 'event type',\n",
    " 'demand loss (mw)',\n",
    " 'number of customers affected',\n",
    " 'state']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error for demand loss (mw): 1825.491133187089\n",
      "Root Mean Squared Error for number of customers affected: 309597.56463220384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "df = df_3_5.copy()\n",
    "\n",
    "categorical_features = ['month', 'area affected', 'nerc region', 'alert criteria', 'event type', 'state']\n",
    "datetime_features = ['time event began', 'time of restoration']\n",
    "target_columns = ['demand loss (mw)', 'number of customers affected']\n",
    "\n",
    "# Convert datetime columns to numeric features\n",
    "for datetime_feature in datetime_features:\n",
    "    df[datetime_feature + '_day'] = df[datetime_feature].dt.day\n",
    "    df[datetime_feature + '_hour'] = df[datetime_feature].dt.hour\n",
    "\n",
    "# encode categorical features with get_dummies\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "# Create a new DataFrame with only original columns\n",
    "df_lr = df.copy()\n",
    "\n",
    "# ...\n",
    "\n",
    "# Iterate over target columns\n",
    "for target_column in target_columns:\n",
    "    # Split the data into sets with and without missing values\n",
    "    data_with_missing = df_encoded[df_encoded[target_column].isnull()]\n",
    "    data_without_missing = df_encoded.dropna(subset=[target_column])\n",
    "\n",
    "    # Split the data into features (X) and target variable (y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data_without_missing[list(df_encoded.columns[df_encoded.columns.str.startswith('month')]) +\n",
    "                            list(df_encoded.columns[df_encoded.columns.str.endswith('_day')]) +\n",
    "                            list(df_encoded.columns[df_encoded.columns.str.endswith('_hour')])],\n",
    "        data_without_missing[target_column],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Train a linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict missing values\n",
    "    predicted_values = model.predict(data_with_missing[list(df_encoded.columns[df_encoded.columns.str.startswith('month')]) +\n",
    "                                                        list(df_encoded.columns[df_encoded.columns.str.endswith('_day')]) +\n",
    "                                                        list(df_encoded.columns[df_encoded.columns.str.endswith('_hour')])])\n",
    "\n",
    "    # Clip negative predictions to zero\n",
    "    predicted_values = np.maximum(predicted_values, 0)\n",
    "\n",
    "    # Convert 'number of customers affected' column to integers\n",
    "    predicted_values = predicted_values.round().astype(int)\n",
    "\n",
    "    # Fill missing values in the original DataFrame\n",
    "    df_lr.loc[df_lr[target_column].isnull(), target_column] = predicted_values\n",
    "\n",
    "    # Ensure non-negative values for demand loss\n",
    "    df_lr[target_column] = np.maximum(df_lr[target_column], 0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    print(f'Root Mean Squared Error for {target_column}: {rmse}')\n",
    "\n",
    "# Drop additional day and hour columns from the final DataFrame\n",
    "df_lr.drop(columns=['time event began_day', 'time event began_hour', 'time of restoration_day', 'time of restoration_hour'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr['number of customers affected'] = df_lr['number of customers affected'].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3834 entries, 0 to 3833\n",
      "Data columns (total 10 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   month                         3834 non-null   object        \n",
      " 1   time event began              3834 non-null   datetime64[ns]\n",
      " 2   time of restoration           3834 non-null   datetime64[ns]\n",
      " 3   area affected                 3834 non-null   object        \n",
      " 4   nerc region                   3834 non-null   object        \n",
      " 5   alert criteria                3834 non-null   object        \n",
      " 6   event type                    3834 non-null   object        \n",
      " 7   demand loss (mw)              3834 non-null   float64       \n",
      " 8   number of customers affected  3834 non-null   int32         \n",
      " 9   state                         3834 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(1), int32(1), object(6)\n",
      "memory usage: 284.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_lr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = df_lr.rename(str.upper, axis='columns')\n",
    "df_lr.to_excel('../data/processed/DOE_LR.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = df_3_5.copy()\n",
    "\n",
    "categorical_features = ['month', 'area affected', 'nerc region', 'alert criteria', 'event type', 'state']\n",
    "datetime_features = ['time event began', 'time of restoration']\n",
    "\n",
    "# Convert datetime columns to float\n",
    "for datetime_feature in datetime_features:\n",
    "    df[datetime_feature + '_float'] = df[datetime_feature].astype('int64') // 10**9  # Convert to seconds and int64\n",
    "\n",
    "# Drop the original datetime columns\n",
    "df = df.drop(columns=datetime_features)\n",
    "\n",
    "# Identify numeric columns for imputation\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Apply KNN imputation only to numeric columns\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df[numeric_columns] = imputer.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Convert imputed float columns back to datetime\n",
    "for datetime_feature in datetime_features:\n",
    "    original_feature_name = datetime_feature + '_float'\n",
    "    df[datetime_feature] = pd.to_datetime(df[original_feature_name], unit='s')\n",
    "\n",
    "# Drop the intermediate float columns\n",
    "df_knn = df.drop(columns=[datetime_feature + '_float' for datetime_feature in datetime_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3834 entries, 0 to 3833\n",
      "Data columns (total 10 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   month                         3834 non-null   object        \n",
      " 1   area affected                 3834 non-null   object        \n",
      " 2   nerc region                   3834 non-null   object        \n",
      " 3   alert criteria                3834 non-null   object        \n",
      " 4   event type                    3834 non-null   object        \n",
      " 5   demand loss (mw)              3834 non-null   float64       \n",
      " 6   number of customers affected  3834 non-null   float64       \n",
      " 7   state                         3834 non-null   object        \n",
      " 8   time event began              3834 non-null   datetime64[ns]\n",
      " 9   time of restoration           3834 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(2), object(6)\n",
      "memory usage: 299.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_knn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = df_knn.rename(str.upper, axis='columns')\n",
    "df_knn.to_excel('../data/processed/DOE_KNN.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = pd.read_excel('../data/processed/DOE_knn.xlsx')\n",
    "df_knn = df_knn.rename(str.lower, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_3_5.copy()\n",
    "# fillna for \"demand loss\" based specific to broad grouping\n",
    "\n",
    "df_final['demand loss (mw)'] = df_final.groupby(['event type','state'])['demand loss (mw)'].transform(lambda x: x.fillna(x.mean()))\n",
    "df_final['demand loss (mw)'] = df_final.groupby(['event type','nerc region'])['demand loss (mw)'].transform(lambda x: x.fillna(x.mean()))\n",
    "df_final['demand loss (mw)'] = df_final.groupby(['event type'])['demand loss (mw)'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "df_final['demand loss (mw)'] = df_final['demand loss (mw)'].round(2)\n",
    "\n",
    "# fillna for \"number of customers affected\" based on based specific to broad grouping\n",
    "df_final['number of customers affected'] = df_final.groupby(['event type','state'])['number of customers affected'].transform(lambda x: x.fillna(x.mean()))\n",
    "df_final['number of customers affected'] = df_final.groupby(['event type','nerc region'])['number of customers affected'].transform(lambda x: x.fillna(x.mean()))\n",
    "df_final['number of customers affected'] = df_final.groupby(['event type'])['number of customers affected'].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "df_final['number of customers affected'] = df_final['number of customers affected'].round(0).astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.rename(str.upper, axis='columns')\n",
    "df_final.to_excel('../data/processed/DOE_FINAL.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_excel('../data/processed/DOE_FINAL.xlsx')\n",
    "df_final = df_final.rename(str.lower, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = df_lr.rename(str.upper, axis='columns')\n",
    "df_lr.to_excel('../data/processed/DOE_LR.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = pd.read_excel('../data/processed/DOE_LR.xlsx')\n",
    "df_lr = df_lr.rename(str.lower, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      2409.000000\n",
       "mean        480.227522\n",
       "std        3317.366302\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           7.000000\n",
       "75%         250.000000\n",
       "max      133200.000000\n",
       "Name: demand loss (mw), dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_5['demand loss (mw)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      3834.000000\n",
       "mean        505.231899\n",
       "std        2641.149764\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%         180.000000\n",
       "75%         503.750000\n",
       "max      133200.000000\n",
       "Name: demand loss (mw), dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr['demand loss (mw)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      3834.000000\n",
       "mean        499.766813\n",
       "std        2796.793002\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%          93.600000\n",
       "75%         300.000000\n",
       "max      133200.000000\n",
       "Name: demand loss (mw), dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_knn['demand loss (mw)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      3834.000000\n",
       "mean        559.198391\n",
       "std        3147.493060\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%         104.960000\n",
       "75%         400.000000\n",
       "max      133200.000000\n",
       "Name: demand loss (mw), dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['demand loss (mw)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.124000e+03\n",
       "mean     1.041592e+05\n",
       "std      2.711622e+05\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      3.937650e+04\n",
       "75%      1.050000e+05\n",
       "max      4.645572e+06\n",
       "Name: number of customers affected, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3_5['number of customers affected'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.834000e+03\n",
       "mean     1.034490e+05\n",
       "std      2.456173e+05\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      5.764000e+04\n",
       "75%      1.130000e+05\n",
       "max      4.645572e+06\n",
       "Name: number of customers affected, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lr['number of customers affected'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.834000e+03\n",
       "mean     1.091359e+05\n",
       "std      2.549270e+05\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      5.208320e+04\n",
       "75%      1.184174e+05\n",
       "max      4.645572e+06\n",
       "Name: number of customers affected, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_knn['number of customers affected'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.834000e+03\n",
       "mean     1.101833e+05\n",
       "std      3.260802e+05\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      2.591700e+04\n",
       "75%      1.070000e+05\n",
       "max      4.645572e+06\n",
       "Name: number of customers affected, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['number of customers affected'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing US population (see `us_populationd.xlsx`), we shoud expect a high standard deviation due to the extreme difference in state populations. df_final grouping first by state gives a more accurate distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Missing Non-Event Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df_full = pd.read_excel('../data/processed/DOE_FINAL.xlsx')\n",
    "df_lr = df_lr.rename(str.lower, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\ds_projects\\maven-challenge\\Maven-Power-Outage-Challenge\\notebooks\\notebook.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ds_projects/maven-challenge/Maven-Power-Outage-Challenge/notebooks/notebook.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_full\u001b[39m.\u001b[39mto_excel(\u001b[39m'\u001b[39m\u001b[39m../data/processed/DOE_full.xlsx\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_full' is not defined"
     ]
    }
   ],
   "source": [
    "df_lr = df_lr.rename(str.upper, axis='columns')\n",
    "df_full.to_excel('../data/processed/DOE_FULL.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
